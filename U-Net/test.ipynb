{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self , in_channels , out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels , out_channels, kernel_size=3 , stride= 1 , padding=1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels , out_channels=out_channels , kernel_size = 3, stride=1 , padding = 1 , bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self , x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self , in_channels=3 , out_channels=1 , features = [64,128,256,512]):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.donws = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.maxpoll = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        \n",
    "        # Down sampling part \n",
    "        for feature in features:\n",
    "            self.donws.append(DoubleConv(self.in_channels , feature))\n",
    "            self.in_channels = feature\n",
    "        \n",
    "        # Up samping part\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.ConvTranspose2d(feature*2 , feature , kernel_size=2 ,stride = 2))\n",
    "            self.ups.append(DoubleConv(feature*2 , feature))\n",
    "        \n",
    "        # Bottelneck\n",
    "        self.bottleneck = DoubleConv(features[-1] , features[-1]*2)\n",
    "        \n",
    "        # Final conv layer(1x1)\n",
    "        self.fianl_conv = nn.Conv2d(features[0], out_channels, kernel_size=1 , stride=1)\n",
    "        \n",
    "        \n",
    "    def forward(self , x):\n",
    "        skip_connections = []\n",
    "        # Down sapling part\n",
    "        for down in self.donws:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.maxpoll(x)\n",
    "        # Bottelencek\n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        skip_connections = skip_connections[::-1]\n",
    "        # up sampling \n",
    "        for idx in range(0,len(self.ups),2): # 짝수 번째에서 up samping , 홀수 번째에 DoubleCOnv\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, skip_connection.shape[2:] , antialias=True)\n",
    "            # (B,C,H,W)에서 채널에 대하여 concat연산\n",
    "            concat_x = torch.cat((skip_connection , x) ,dim=1)\n",
    "            x = self.ups[idx+1](concat_x)\n",
    "        \n",
    "        return self.fianl_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import UNetDataset\n",
    "traindataset = UNetDataset()\n",
    "_, mask = traindataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280, 1918])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[mask == 255] = 1\n",
    "mask_t = torch.tensor(mask , dtype=torch.float).unsqueeze(0)\n",
    "mask_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Bar: 100%|██████████| 100/100 [00:01<00:00, 59.45 epoch/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "for i in tqdm(range(100), desc = \"Process Bar\" , unit = \" epoch\"):\n",
    "    time.sleep(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10.0/10.0 [00:01<00:00, 9.18items/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# scale 인자를 사용하여 자동 스케일링을 조절\n",
    "with tqdm(total=10, unit=\"items\", unit_scale=True, unit_divisor=10,colour=\"\") as pbar:\n",
    "    for i in range(10):\n",
    "        time.sleep(0.1)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "def train_fn(model , loader , optimizer , loss_fn , device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    loop = tqdm(loader ,desc = \"Traning\" , unit = \"iter\")\n",
    "    for x,y in loader :\n",
    "        x =x.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(x)    \n",
    "        loss = loss_fn(pred , y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # caculate metric(train_acc , loss)\n",
    "        train_loss+=loss.item()\n",
    "        train_acc += ((torch.argmax(pred , dim=1)==y).sum().item() / len(y))\n",
    "        # loop update\n",
    "        loop.update(1)\n",
    "        \n",
    "    train_loss /= len(loader)\n",
    "    train_acc /= len(loader)\n",
    "    loop.close()\n",
    "    return train_loss , train_acc\n",
    "\n",
    "def test_fn(model , loader , loss_fn , device):\n",
    "    model.eval()\n",
    "    test_loss =0\n",
    "    test_acc = 0\n",
    "    with torch.inference_mode():\n",
    "        loop = tqdm(loader ,desc = \"Test\" , unit = \"iter\")        \n",
    "        for x ,y in loader:\n",
    "            x =x.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(x)    \n",
    "            test_loss += loss_fn(pred , y).item()\n",
    "            test_acc += (torch.argmax(pred,dim=1)==y).sum() / len(y)\n",
    "\n",
    "            # loop update\n",
    "            loop.update(1)\n",
    "        loop.close()\n",
    "    test_loss /= len(loader)\n",
    "    test_acc /= len(loader)\n",
    "    return test_loss , test_acc\n",
    "\n",
    "def train(model,\n",
    "          train_loader,\n",
    "          val_loader,\n",
    "          optimizer,\n",
    "          loss_fn,\n",
    "          device,\n",
    "          epochs):\n",
    "    best_loss = None\n",
    "    for epoch in range(epochs):\n",
    "        train_loss , train_acc = train_fn(model, train_loader , optimizer , loss_fn , device)\n",
    "        val_loss , val_acc = test_fn(model , val_loader , loss_fn , device)\n",
    "        # print result\n",
    "        print(f\"[{epoch+1}/{epochs}] | Train_loss: {train_loss:.5f} , Train_acc : {train_acc*100:.2f}% \\\n",
    "                | Val_loss: {val_loss:.5f} , Val_acc : {val_acc*100:.2f}%\")\n",
    "        # model save\n",
    "        if best_loss is None:\n",
    "            best_loss = train_loss\n",
    "            save_checkpoint(model , optimizer , \"best\" , \"/model\" , epoch = epoch , loss = train_loss , acc = train_acc)\n",
    "        elif best_loss > train_loss:\n",
    "            print(\"Best!!\")\n",
    "            best_loss = train_loss\n",
    "            save_checkpoint(model , optimizer , \"best\" , \"/model\" , epoch = epoch , loss = train_loss , acc = train_acc)\n",
    "        else:\n",
    "            save_checkpoint(model , optimizer , \"last\" , \"/model\" , epoch = epoch , loss = train_loss , acc = train_acc)\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "def save_checkpoint(model , optimizer, name , path , **results):\n",
    "    check_point = {}\n",
    "    check_point.update({\"model_state_dict\" : model.state_dict()})\n",
    "    check_point.update({\"optimizer_state_dict\" : optimizer.state_dict()})\n",
    "    check_point.update(results)\n",
    "    model_dir = Path(path)\n",
    "    if model_dir.is_dir() and not model_dir.exists():\n",
    "        model_dir.mkdir(parents=True , exist_ok=True)\n",
    "        \n",
    "    model_path = model_dir / str(name+\".pth\")\n",
    "    torch.save(check_point, model_path)\n",
    "\n",
    "def load_checkpoint(path , model , optimizer):\n",
    "    check_point = torch.load(path)\n",
    "    model.load_state_dict(check_point['model_state_dict'])\n",
    "    optimizer.load_state_dict(check_point['optimizer_state_dict'])\n",
    "        \n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 37957.50it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10041.43it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10000.72it/s]\n",
      "100%|██████████| 10/10 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    for  j in tqdm(range(10) , position=None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021544330233656045"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sin(1/math.pow(10000,4/6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17],\n",
      "        [18, 19, 20, 21, 22, 23]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 15,  51,  87, 123])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor(range(24)).reshape(4,-1)\n",
    "print(a)\n",
    "torch.einsum(\"ij->i\",a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "data_dir = Path(\"/kaggle/input/dogs-vs-cats\")\n",
    "with zipfile.ZipFile(data_dir/\"train.zip\") as zip_ref:\n",
    "    files = zip_ref.infolist()\n",
    "    for file in tqdm(files):\n",
    "        zip_ref.extract(file , path=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "a = pd.DataFrame()\n",
    "a.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self ,home_dir, images , transform = None):\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "        self.class_to_index = {\"cat\" : 0 ,\"dog\" : 1}\n",
    "        self.home_dir = Path(home_dir)\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    def __getitem__(self , idx):\n",
    "        img = Image.open(self.home_dir.joinpath(self.images[idx]))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            ag = self.transform(image=img)\n",
    "            img = ag[\"image\"]\n",
    "        label = self.class_to_index[self.images[idx].split(\".\")[0]]\n",
    "        label = torch.FloatTensor(label)\n",
    "        return img , label\n",
    "def get_dataloader(home_dir , train_image , val_image , batch_size , train_transform = None , val_transform = None):\n",
    "    train_dataset = CatDogDataset(home_dir , train_image , train_transform)\n",
    "    val_dataset = CatDogDataset(home_dir , val_image , val_transform)\n",
    "    train_loader = DataLoader(train_dataset , batch_size = batch_size , shuffle=True )\n",
    "    test_loader = DataLoader(val_dataset , batch_size=batch_size , shuffle=False)\n",
    "    return train_loader , test_loader\n",
    "\n",
    "# Setting transform\n",
    "train_transform = A.Compose( [ \n",
    "    A.Resize(240,240z),\n",
    "    A.OneOf([\n",
    "        A.HorizontalFlip(p=0.3),\n",
    "        A.Rotate(limit = 20 ,p=0.5 , value = 0)\n",
    "    ],p=0.5),\n",
    "    \n",
    "    \n",
    "    A.Sharpen(p=0.3, lightness=(0.9,1.0)),\n",
    "    A.Normalize(mean =[0.485, 0.456, 0.406] , std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "val_transform = A.Compose( [ \n",
    "    A.Normalize(mean =[0.485, 0.456, 0.406] , std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "train_loader , val_loader = get_dataloader(\"./train\" , train_img , val_img , 32 , train_transform , val_transform)\n",
    "img , label = next(iter(train_loader))\n",
    "img.shape , label.shape\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 28, 28])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self , in_channels , ch1x1 , ch3x3_reduct , ch3x3 , ch5x5_reduct , ch5x5 , pool ):\n",
    "        super(InceptionModule , self).__init__()\n",
    "        \n",
    "        self.conv1x1 = nn.Conv2d(in_channels , ch1x1 , kernel_size=1)\n",
    "        self.conv3x3 = nn.Sequential(BaseConv2d(in_channels , ch3x3_reduct , kernel_size=1),\n",
    "                                     BaseConv2d(ch3x3_reduct,ch3x3 , kernel_size=3,padding=1))\n",
    "        self.conv5x5 = nn.Sequential(BaseConv2d(in_channels , ch5x5_reduct , kernel_size=1),\n",
    "                                     BaseConv2d(ch5x5_reduct , ch5x5 , kernel_size=5 , padding=2))\n",
    "        self.pool = nn.Sequential(nn.MaxPool2d(kernel_size=3,padding=1,stride=1),\n",
    "                                  nn.Conv2d(in_channels , pool , kernel_size=1))\n",
    "    def forward(self ,x ):\n",
    "        x1 = self.conv1x1(x)\n",
    "        x2 = self.conv3x3(x)\n",
    "        x3 = self.conv5x5(x)\n",
    "        x4 = self.pool(x)\n",
    "        \n",
    "        return torch.cat([x1,x2,x3,x4] , dim=1)\n",
    "    \n",
    "\n",
    "class BaseConv2d(nn.Module):\n",
    "    def __init__(self , in_channels , out_channels  , **kwards):\n",
    "        super(BaseConv2d, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(in_channels , out_channels  , **kwards)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self , x):\n",
    "        return self.relu(self.conv2d(x))\n",
    "\n",
    "class AuxMoudle(nn.Module):\n",
    "    def __init__(self , in_channels , num_classes):\n",
    "        super(AuxMoudle,self).__init__()\n",
    "        self.aux = nn.Sequential(nn.AvgPool2d(kernel_size=5 , stride=3),\n",
    "                                 BaseConv2d(in_channels,128,kernel_size = 1),\n",
    "                                 nn.Flatten(start_dim=1),\n",
    "                                 nn.Linear(4*4*128,1024),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Dropout(p=0.7),\n",
    "                                 nn.Linear(1024,num_classes))\n",
    "    def forward(self, x):\n",
    "        return self.aux(x)\n",
    "\n",
    "# image size =(3x224x224) \n",
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self, in_channels , num_classes):\n",
    "        super().__init__()\n",
    "        self.training =True\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Sequential(BaseConv2d(3,64,kernel_size = 7,stride=2,padding=3),\n",
    "                                 nn.MaxPool2d(kernel_size=3,stride=2,padding=1),\n",
    "                                 nn.LocalResponseNorm(2))\n",
    "        self.conv2 = nn.Sequential(BaseConv2d(64,192,kernel_size=1),\n",
    "                                 BaseConv2d(192,192,kernel_size=3,padding=1),\n",
    "                                 nn.LocalResponseNorm(2),\n",
    "                                 nn.MaxPool2d(kernel_size=3,stride=2,padding=1))\n",
    "        self.inception3_a = InceptionModule(192,64,96,128,16,32,32)\n",
    "        self.inception3_b = InceptionModule(256,128,128,192,32,96,64)\n",
    "        self.aux1 = AuxMoudle(512,self.num_classes)\n",
    "        self.inception4_a = InceptionModule(480,192,96,208,16,48,64)\n",
    "        self.inception4_b = InceptionModule(512,160,112,224,24,64,64)\n",
    "        self.inception4_c = InceptionModule(512,128,128,256,24,64,64)\n",
    "        self.aux2 = AuxMoudle(528,self.num_classes)\n",
    "        self.inception4_d = InceptionModule(512,112,144,288,32,64,64)\n",
    "        self.inception4_e = InceptionModule(528,256,160,320,32,128,128)\n",
    "        self.inception5_a = InceptionModule(832,256,160,320,32,128,128)\n",
    "        self.inception5_b = InceptionModule(832,384,192,384,48,128,128)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(3,stride=2,padding=1)\n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        self.fc = nn.Sequential(nn.Flatten(start_dim=1),\n",
    "                                nn.Dropout(p=0.4),\n",
    "                                nn.Linear(1024,num_classes))\n",
    "    \n",
    "    def forward(self , x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.inception3_a(x)\n",
    "        x = self.inception3_b(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.inception4_a(x)\n",
    "        x = self.inception4_b(x)\n",
    "        \n",
    "        if self.training:\n",
    "            out1 = self.aux1(x)\n",
    "        x = self.inception4_c(x)\n",
    "        x = self.inception4_d(x)\n",
    "        if self.training:\n",
    "            out2 = self.aux2(x)\n",
    "        x = self.inception4_e(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.inception5_a(x)\n",
    "        x = self.inception5_b(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.fc(x)\n",
    "        if self.training:\n",
    "            return [x , out1 , out2]\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "GoogleNet                                [16, 1000]                6,379,728\n",
       "├─Sequential: 1-1                        [16, 64, 56, 56]          --\n",
       "│    └─BaseConv2d: 2-1                   [16, 64, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-1                  [16, 64, 112, 112]        9,472\n",
       "│    │    └─ReLU: 3-2                    [16, 64, 112, 112]        --\n",
       "│    └─MaxPool2d: 2-2                    [16, 64, 56, 56]          --\n",
       "│    └─LocalResponseNorm: 2-3            [16, 64, 56, 56]          --\n",
       "├─Sequential: 1-2                        [16, 192, 28, 28]         --\n",
       "│    └─BaseConv2d: 2-4                   [16, 192, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-3                  [16, 192, 56, 56]         12,480\n",
       "│    │    └─ReLU: 3-4                    [16, 192, 56, 56]         --\n",
       "│    └─BaseConv2d: 2-5                   [16, 192, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-5                  [16, 192, 56, 56]         331,968\n",
       "│    │    └─ReLU: 3-6                    [16, 192, 56, 56]         --\n",
       "│    └─LocalResponseNorm: 2-6            [16, 192, 56, 56]         --\n",
       "│    └─MaxPool2d: 2-7                    [16, 192, 28, 28]         --\n",
       "├─InceptionModule: 1-3                   [16, 256, 28, 28]         --\n",
       "│    └─Conv2d: 2-8                       [16, 64, 28, 28]          12,352\n",
       "│    └─Sequential: 2-9                   [16, 128, 28, 28]         --\n",
       "│    │    └─BaseConv2d: 3-7              [16, 96, 28, 28]          18,528\n",
       "│    │    └─BaseConv2d: 3-8              [16, 128, 28, 28]         110,720\n",
       "│    └─Sequential: 2-10                  [16, 32, 28, 28]          --\n",
       "│    │    └─BaseConv2d: 3-9              [16, 16, 28, 28]          3,088\n",
       "│    │    └─BaseConv2d: 3-10             [16, 32, 28, 28]          12,832\n",
       "│    └─Sequential: 2-11                  [16, 32, 28, 28]          --\n",
       "│    │    └─MaxPool2d: 3-11              [16, 192, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-12                 [16, 32, 28, 28]          6,176\n",
       "├─InceptionModule: 1-4                   [16, 480, 28, 28]         --\n",
       "│    └─Conv2d: 2-12                      [16, 128, 28, 28]         32,896\n",
       "│    └─Sequential: 2-13                  [16, 192, 28, 28]         --\n",
       "│    │    └─BaseConv2d: 3-13             [16, 128, 28, 28]         32,896\n",
       "│    │    └─BaseConv2d: 3-14             [16, 192, 28, 28]         221,376\n",
       "│    └─Sequential: 2-14                  [16, 96, 28, 28]          --\n",
       "│    │    └─BaseConv2d: 3-15             [16, 32, 28, 28]          8,224\n",
       "│    │    └─BaseConv2d: 3-16             [16, 96, 28, 28]          76,896\n",
       "│    └─Sequential: 2-15                  [16, 64, 28, 28]          --\n",
       "│    │    └─MaxPool2d: 3-17              [16, 256, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-18                 [16, 64, 28, 28]          16,448\n",
       "├─MaxPool2d: 1-5                         [16, 480, 14, 14]         --\n",
       "├─InceptionModule: 1-6                   [16, 512, 14, 14]         --\n",
       "│    └─Conv2d: 2-16                      [16, 192, 14, 14]         92,352\n",
       "│    └─Sequential: 2-17                  [16, 208, 14, 14]         --\n",
       "│    │    └─BaseConv2d: 3-19             [16, 96, 14, 14]          46,176\n",
       "│    │    └─BaseConv2d: 3-20             [16, 208, 14, 14]         179,920\n",
       "│    └─Sequential: 2-18                  [16, 48, 14, 14]          --\n",
       "│    │    └─BaseConv2d: 3-21             [16, 16, 14, 14]          7,696\n",
       "│    │    └─BaseConv2d: 3-22             [16, 48, 14, 14]          19,248\n",
       "│    └─Sequential: 2-19                  [16, 64, 14, 14]          --\n",
       "│    │    └─MaxPool2d: 3-23              [16, 480, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-24                 [16, 64, 14, 14]          30,784\n",
       "├─InceptionModule: 1-7                   [16, 512, 14, 14]         --\n",
       "│    └─Conv2d: 2-20                      [16, 160, 14, 14]         82,080\n",
       "│    └─Sequential: 2-21                  [16, 224, 14, 14]         --\n",
       "│    │    └─BaseConv2d: 3-25             [16, 112, 14, 14]         57,456\n",
       "│    │    └─BaseConv2d: 3-26             [16, 224, 14, 14]         226,016\n",
       "│    └─Sequential: 2-22                  [16, 64, 14, 14]          --\n",
       "│    │    └─BaseConv2d: 3-27             [16, 24, 14, 14]          12,312\n",
       "│    │    └─BaseConv2d: 3-28             [16, 64, 14, 14]          38,464\n",
       "│    └─Sequential: 2-23                  [16, 64, 14, 14]          --\n",
       "│    │    └─MaxPool2d: 3-29              [16, 512, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-30                 [16, 64, 14, 14]          32,832\n",
       "├─InceptionModule: 1-8                   [16, 512, 14, 14]         --\n",
       "│    └─Conv2d: 2-24                      [16, 128, 14, 14]         65,664\n",
       "│    └─Sequential: 2-25                  [16, 256, 14, 14]         --\n",
       "│    │    └─BaseConv2d: 3-31             [16, 128, 14, 14]         65,664\n",
       "│    │    └─BaseConv2d: 3-32             [16, 256, 14, 14]         295,168\n",
       "│    └─Sequential: 2-26                  [16, 64, 14, 14]          --\n",
       "│    │    └─BaseConv2d: 3-33             [16, 24, 14, 14]          12,312\n",
       "│    │    └─BaseConv2d: 3-34             [16, 64, 14, 14]          38,464\n",
       "│    └─Sequential: 2-27                  [16, 64, 14, 14]          --\n",
       "│    │    └─MaxPool2d: 3-35              [16, 512, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-36                 [16, 64, 14, 14]          32,832\n",
       "├─InceptionModule: 1-9                   [16, 528, 14, 14]         --\n",
       "│    └─Conv2d: 2-28                      [16, 112, 14, 14]         57,456\n",
       "│    └─Sequential: 2-29                  [16, 288, 14, 14]         --\n",
       "│    │    └─BaseConv2d: 3-37             [16, 144, 14, 14]         73,872\n",
       "│    │    └─BaseConv2d: 3-38             [16, 288, 14, 14]         373,536\n",
       "│    └─Sequential: 2-30                  [16, 64, 14, 14]          --\n",
       "│    │    └─BaseConv2d: 3-39             [16, 32, 14, 14]          16,416\n",
       "│    │    └─BaseConv2d: 3-40             [16, 64, 14, 14]          51,264\n",
       "│    └─Sequential: 2-31                  [16, 64, 14, 14]          --\n",
       "│    │    └─MaxPool2d: 3-41              [16, 512, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-42                 [16, 64, 14, 14]          32,832\n",
       "├─InceptionModule: 1-10                  [16, 832, 14, 14]         --\n",
       "│    └─Conv2d: 2-32                      [16, 256, 14, 14]         135,424\n",
       "│    └─Sequential: 2-33                  [16, 320, 14, 14]         --\n",
       "│    │    └─BaseConv2d: 3-43             [16, 160, 14, 14]         84,640\n",
       "│    │    └─BaseConv2d: 3-44             [16, 320, 14, 14]         461,120\n",
       "│    └─Sequential: 2-34                  [16, 128, 14, 14]         --\n",
       "│    │    └─BaseConv2d: 3-45             [16, 32, 14, 14]          16,928\n",
       "│    │    └─BaseConv2d: 3-46             [16, 128, 14, 14]         102,528\n",
       "│    └─Sequential: 2-35                  [16, 128, 14, 14]         --\n",
       "│    │    └─MaxPool2d: 3-47              [16, 528, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-48                 [16, 128, 14, 14]         67,712\n",
       "├─MaxPool2d: 1-11                        [16, 832, 7, 7]           --\n",
       "├─InceptionModule: 1-12                  [16, 832, 7, 7]           --\n",
       "│    └─Conv2d: 2-36                      [16, 256, 7, 7]           213,248\n",
       "│    └─Sequential: 2-37                  [16, 320, 7, 7]           --\n",
       "│    │    └─BaseConv2d: 3-49             [16, 160, 7, 7]           133,280\n",
       "│    │    └─BaseConv2d: 3-50             [16, 320, 7, 7]           461,120\n",
       "│    └─Sequential: 2-38                  [16, 128, 7, 7]           --\n",
       "│    │    └─BaseConv2d: 3-51             [16, 32, 7, 7]            26,656\n",
       "│    │    └─BaseConv2d: 3-52             [16, 128, 7, 7]           102,528\n",
       "│    └─Sequential: 2-39                  [16, 128, 7, 7]           --\n",
       "│    │    └─MaxPool2d: 3-53              [16, 832, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-54                 [16, 128, 7, 7]           106,624\n",
       "├─InceptionModule: 1-13                  [16, 1024, 7, 7]          --\n",
       "│    └─Conv2d: 2-40                      [16, 384, 7, 7]           319,872\n",
       "│    └─Sequential: 2-41                  [16, 384, 7, 7]           --\n",
       "│    │    └─BaseConv2d: 3-55             [16, 192, 7, 7]           159,936\n",
       "│    │    └─BaseConv2d: 3-56             [16, 384, 7, 7]           663,936\n",
       "│    └─Sequential: 2-42                  [16, 128, 7, 7]           --\n",
       "│    │    └─BaseConv2d: 3-57             [16, 48, 7, 7]            39,984\n",
       "│    │    └─BaseConv2d: 3-58             [16, 128, 7, 7]           153,728\n",
       "│    └─Sequential: 2-43                  [16, 128, 7, 7]           --\n",
       "│    │    └─MaxPool2d: 3-59              [16, 832, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-60                 [16, 128, 7, 7]           106,624\n",
       "├─AvgPool2d: 1-14                        [16, 1024, 1, 1]          --\n",
       "├─Sequential: 1-15                       [16, 1000]                --\n",
       "│    └─Flatten: 2-44                     [16, 1024]                --\n",
       "│    └─Dropout: 2-45                     [16, 1024]                --\n",
       "│    └─Linear: 2-46                      [16, 1000]                1,025,000\n",
       "==========================================================================================\n",
       "Total params: 13,607,784\n",
       "Trainable params: 13,607,784\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 36.89\n",
       "==========================================================================================\n",
       "Input size (MB): 9.63\n",
       "Forward/backward pass size (MB): 464.46\n",
       "Params size (MB): 28.91\n",
       "Estimated Total Size (MB): 503.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "model =  GoogleNet(3,1000)\n",
    "Batch_size = 16\n",
    "summary(model , input_size = (Batch_size, 3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1000]), torch.Size([16, 1000]), torch.Size([16, 1000]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = GoogleNet(3,1000)\n",
    "x, out1 , out2 = m(torch.randn(16,3,224,224))\n",
    "x.shape, out1.shape, out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters() , lr = 1e-4)\n",
    "torch.nn.BCEWithLogitsLoss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
